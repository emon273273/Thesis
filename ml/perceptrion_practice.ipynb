{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "St7pirCoHSjY"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# import sklearn.neural_network\n",
        "\n",
        "# xs=np.array([\n",
        "#     0,0,\n",
        "#     0,1,\n",
        "#     1,0,\n",
        "#     1,1\n",
        "# ]).reshape(4,2)\n",
        "# ys=np.array([0,1,1,0])#([0, 1, 1, 0])\n",
        "# ys.reshape(4,)\n",
        "# model=sklearn.neural_network.MLPClassifier(activation=\"relu\",max_iter=10000,learning_rate=\"constant\",hidden_layer_sizes=(4)) #hidden layer akta and neuron 3 ta aro ->hidden_layer_sizes=(2, 2, 4))#3 hidden layer and first layer and second has 2 neurons and third has 4 neurons .\n",
        "# model.fit(xs,ys)\n",
        "\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "# plt.scatter(xs[:,0], xs[:,1], c=ys, cmap=plt.cm.brg)\n",
        "# plt.show()\n",
        "\n",
        "# print(\"score\",model.score(xs,ys))\n",
        "# print(\"prediction\",model.predict(xs))\n",
        "# print (\"expected\",np.array([0,1,1,0]))\n",
        "# xs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# import matplotlib.pyplot as plt\n",
        "# from sklearn.datasets import load_iris\n",
        "# from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "7GMNOmGBtlbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3I4qtJNV3CPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "heart_disease = fetch_ucirepo(id=45)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = heart_disease.data.features\n",
        "y = heart_disease.data.targets\n",
        "\n",
        "# metadata\n",
        "# print(heart_disease.metadata)\n",
        "\n",
        "# # variable information\n",
        "# print(heart_disease.variables)\n",
        "X.shape\n",
        "y.shape\n",
        "\n",
        "X.shape\n",
        "\n",
        "y.shape\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def mean_squared_error(y_pred, y_true):\n",
        "    return ((y_pred - y_true) ** 2).sum() / (2 * y_pred.size)\n",
        "\n",
        "def accuracy(y_pred, y_true):\n",
        "    if isinstance(y_true, pd.DataFrame):\n",
        "        y_true = y_true.values\n",
        "\n",
        "    acc = y_pred.argmax(axis=1) == y_true.argmax(axis=1)\n",
        "    return acc.mean()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=20, random_state=4)\n",
        "# y_train = np.reshape(y_train, (y_train.shape[0], 1))\n",
        "# y_test = np.reshape(y_test, (y_test.shape[0], 1))\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=20, random_state=4)\n",
        "\n",
        "learning_rate = 0.1\n",
        "iterations = 10000\n",
        "N = y_train.size\n",
        "\n",
        "input_size = 13\n",
        "hidden_size = 2\n",
        "output_size = 1\n",
        "results = pd.DataFrame(columns=['mse', 'accuracy'])\n",
        "\n",
        "np.random.seed(10)\n",
        "\n",
        "W1 = np.random.normal(scale=0.5, size=(input_size, hidden_size))\n",
        "\n",
        "\n",
        "W2 = np.random.normal(scale=0.5, size=(hidden_size, output_size))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "results_list = []\n",
        "\n",
        "for itr in range(iterations):\n",
        "\n",
        "    Z1 = np.dot(X_train, W1)\n",
        "    A1 = sigmoid(Z1)\n",
        "\n",
        "    Z2 = np.dot(A1, W2)\n",
        "    A2 = sigmoid(Z2)\n",
        "\n",
        "\n",
        "    mse = mean_squared_error(A2, y_train)\n",
        "    # acc = accuracy(A2.values, y_train.values)\n",
        "    acc = accuracy(A2, y_train)\n",
        "    results_list.append({\"mse\": mse, \"accuracy\": acc})\n",
        "\n",
        "\n",
        "    E1 = A2 - y_train\n",
        "    dW1 = E1 * A2 * (1 - A2)\n",
        "    E2 = np.dot(dW1, W2.T)\n",
        "    dW2 = E2 * A1 * (1 - A1)\n",
        "\n",
        "\n",
        "    w2_update = np.dot(A1.T, dW1) / N\n",
        "    w1_update = np.dot(X_train.T, dW2) / N\n",
        "\n",
        "    W2 = W2 - learning_rate * w2_update\n",
        "    W1 = W1 - learning_rate * w1_update\n",
        "\n",
        "Z1 = np.dot(X_test, W1)\n",
        "A1 = sigmoid(Z1)\n",
        "Z2 = np.dot(A1, W2)\n",
        "A2 = sigmoid(Z2)\n",
        "\n",
        "acc = accuracy(A2, y_test)\n",
        "print(\"Accuracy is {}\".format(acc))"
      ],
      "metadata": {
        "id": "KIFwVZfk9hDx",
        "outputId": "675c715d-3556-475a-fde9-62e9106e6464",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'ucimlrepo'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b0a2d226f21b>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mucimlrepo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfetch_ucirepo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# fetch dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ucimlrepo'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#  x = pd.DataFrame(iris.data , columns=['SL','SW','PL','PW'])\n",
        "#  y = pd.DataFrame(iris.target , columns=['Target'])\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# %matplotlib inline\n",
        "\n",
        "df=pd.read_csv('/content/drive/MyDrive/versity/Thesis/data/diabetes.csv')\n",
        "\n",
        "df.head(10)\n",
        "\n",
        "df.isnull().sum()\n",
        "\n",
        "#display dataset randomly\n",
        "df.sample(10)\n",
        "\n",
        "#shape of the dataset\n",
        "df.shape\n",
        "\n",
        "\n",
        "df.columns\n",
        "\n",
        "\n",
        "\"\"\"# Split the data frame into X and y\"\"\"\n",
        "\n",
        "target_name='Outcome'\n",
        "y=df['Outcome']\n",
        "X=df.drop(target_name,axis=1)\n",
        "\n",
        "y\n",
        "\n",
        "X.head()\n",
        "\n",
        "\"\"\"# Feature scaling tecniques\n",
        "\n",
        "\"\"\"\n",
        "#standard scaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler=StandardScaler()\n",
        "scaler.fit(X)\n",
        "SSX=scaler.transform(X)\n",
        "SSX\n",
        "#scaler = StandardScaler()\n",
        "#scaler.fit(X_train)\n",
        "#X_train = scaler.transform(X_train)\n",
        "#X_test = scaler.transform(X_test)\n",
        "\"\"\"# Train Test split\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(SSX,y,test_size=0.25,random_state=42)\n",
        "X_train.shape,y_train.shape\n",
        "\n",
        "X_test.shape,y_test.shape\n",
        "\n",
        "\n",
        "#Linear Regression\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "Linearregression=LinearRegression()\n",
        "Linearregression.fit(X_train,y_train)\n",
        "\n",
        "linear_predict=Linearregression.predict(X_test)\n",
        "df=pd.DataFrame({'Actual':y_test,'Predicted':linear_predict}).round(0)\n",
        "df\n",
        "\n",
        "#check accuracy mean\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "mae_for_linear=mean_absolute_error(y_test,linear_predict)\n",
        "print(f\"mean absolute error {mae_for_linear}\")\n",
        "\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# accuracy = accuracy_score(y_test , linear_predict)\n",
        "\n",
        "# Logistic Regression\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr=LogisticRegression()\n",
        "lr.fit(X_train,y_train)\n",
        "lr_predict=lr.predict(X_test)\n",
        "df=pd.DataFrame({'Actual':y_test,'Predicted':lr_predict}).round(0)\n",
        "df\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "mae_for_log=mean_absolute_error(y_test,lr_predict)\n",
        "print(f\"mean absolute error {mae_for_log}\")\n",
        "\n",
        "# KNN Classification\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "range_k = range(1,15)\n",
        "scores = {}\n",
        "scores_list = []\n",
        "for k in range_k:\n",
        "  classifier=KNeighborsClassifier(n_neighbors=k)\n",
        "  classifier.fit(X_train,y_train)\n",
        "  knn_predict=classifier.predict(X_test)\n",
        "  scores[k]=metrics.accuracy_score(y_test,knn_predict)\n",
        "  scores_list.append(metrics.accuracy_score(y_test,knn_predict))\n",
        "\n",
        "result=metrics.confusion_matrix(y_test,knn_predict)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(result)\n",
        "result1 = metrics.classification_report(y_test , knn_predict)\n",
        "print(\"Classification Report:\",)\n",
        "\n",
        "\"\"\"**Now, we will be plotting the relationship between the values of K and the corresponding testing\n",
        "accuracy. It will be done using matplotlib library.**\n",
        "\"\"\"\n",
        "\n",
        "plt.plot(range_k,scores_list)\n",
        "plt.xlabel(\"Values of K\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors = 2)\n",
        "classifier.fit(X_train , y_train)\n",
        "\n",
        "knn_predict=classifier.predict(X_test)\n",
        "df=pd.DataFrame({'Actual':y_test,'Predicted':knn_predict}).round(0)\n",
        "df\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "knn_predict_mean=mean_absolute_error(y_test,knn_predict)\n",
        "print(f\"mean absolute error{knn_predict_mean}\")\n",
        "\n",
        "#naive bayes\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "nb=GaussianNB()\n",
        "nb.fit(X_train,y_train)\n",
        "\n",
        "nb_predict=nb.predict(X_test)\n",
        "df=pd.DataFrame({'Actual':y_test,'Predicted':nb_predict}).round(0)\n",
        "df\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "nb_predict_mean=mean_absolute_error(y_test,nb_predict)\n",
        "print(f\"mean absolute error{nb_predict_mean}\")"
      ],
      "metadata": {
        "id": "UGO0F2g4V4TL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import sklearn.metrics as sm\n",
        "%matplotlib inline\n",
        "iris = datasets.load_iris()\n",
        "print(iris.target_names)\n",
        "x = pd.DataFrame(iris.data , columns=['SL','SW','PL','PW'])\n",
        "y = pd.DataFrame(iris.target , columns=['Target'])\n",
        "iris_k_mean_model = KMeans(n_clusters =3) # we set K = 3\n",
        "iris_k_mean_model.fit(x)\n",
        "\n",
        "predictedY=iris_k_mean_model.predict(x)\n",
        "sm.accuracy_score(predictedY , y['Target'])\n",
        "sm.confusion_matrix(predictedY , y['Target'])\n"
      ],
      "metadata": {
        "id": "yBoXGl_PeXkM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}